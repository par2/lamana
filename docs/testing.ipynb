{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbsphinx": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Run: 2016-03-12 21:13:11\n"
     ]
    }
   ],
   "source": [
    "# Hidden TimeStamp\n",
    "import time, datetime\n",
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('Last Run: {}'.format(st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A guide for testing code prior to submitting pull request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing code with `nose`\n",
    "\n",
    "The current testing utility is `nose`.  From the root directory, you can test all files prepended with \"test_\" by running:\n",
    "\n",
    "    $ nosetests\n",
    "   \n",
    "There are three types of tests contained in the source `lamana` directory:\n",
    "\n",
    "1. module tests: normal test files located in the \"./tests\" directory\n",
    "1. model tests: test files specific for custom models, located in \"./models/tests\"\n",
    "1. controls: .csv files located \"./tests/controls_LT\"\n",
    "\n",
    "Models tests are separated to support an extensibile design for author contributions. This design enables authors to create models and tests together with a single pull request to the standard module directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests for the `utils` module writes and removes temporary files in a root directory called \"export\".  If this directory does not exist, one will be created.  These test check that writing and reading of files are consistent.  Temporary files are prefixed with \"temp\", but should be removed by these test functions."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    The locations for tests may change in future releases."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note:\n",
    "\n",
    "    Running ``nosetests`` on all tests can take a long time (e.g. >10 minutes for ~200 tests).  Testing a specific test modules may be more effective by temporarily removing unchanged test modules prior to running this command.  Add these tests back after this micro-testing is satisfactory.  This is easily done with GitHub Windows \"discard changes\" for deleted files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control files\n",
    "\n",
    "\n",
    "LamAna maintains .csv files with expected data for different lamanate configurations.  These files are tested with the `test_controls` module.  This module reads each control file and parses information such as layer numbers, number of points per layer and geometry.  Control files are named by these variables.\n",
    "\n",
    "Controls files can be created manually, but it may be simpler to make and then edit a starter file.  This process can be expedited for multiple files by passing LaminateModels into the `utils.tools.write_csv()` function.  This function will create a csv file for every LaminateModel, which can be altered as desired and tested by copying into the \"lamana/tests/controls_LT\" folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Coverage\n",
    "\n",
    "We use the following tools and commands to assess test coverage.  `nose-cov` helps to combine coverage reports for sub-packages automatically.  The remaining flags will report missing lines for the source directory. \n",
    "\n",
    "```\n",
    "$ pip install coverage, nose-cov\n",
    "$ nosetests --with-cov --cov lamana\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```    \n",
    "$ nosetests --with-cov --cov-report term-missing --cov lamana\n",
    "```\n",
    "LamAna aims for the highest \"reasonable\" coverage for core modules.  A separate ideology must be developed for testing `output_` as plots are tricky to test fully. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Deployment\n",
    "\n",
    "Prior to a release, it is fitting to test any API demonstration notebooks in a  development virtual environment and release branch.  A simple way to validate notebook cells without errors is to use the [`runipy` tool](https://github.com/paulgb/runipy).  This tool will run notebook cells in the command prompt and halt if errors are found.  The command is simple to apply to a notebook:\n",
    "\n",
    "```\n",
    "$ pip install runipy\n",
    "$ runipy <demo>.ipynb\n",
    "```\n",
    "\n",
    "If no errors were found, your tested API works, and you can advance in the release workflow."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    There are occassions where `runipy` throws an error for cells that run normally in the Jupyter notebook.  It is then reasonable to simply run all cells in a notebook as usual.  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
