{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbsphinx": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Run: 2016-02-13 22:00:46\n"
     ]
    }
   ],
   "source": [
    "# Hidden TimeStamp\n",
    "import time, datetime\n",
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('Last Run: {}'.format(st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Package Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Module: `input_`\n",
    "\n",
    "### `Geometry` class\n",
    "\n",
    "This class is designed for parsing a user input (assumed a geometry string) and converts it into a Geometry object. \n",
    "\n",
    "```\n",
    "    LamAna.input_.Geometry(geo_input) --> <Geometry object>\n",
    "    \n",
    "```\n",
    "\n",
    "A geometry string is formatted to a General Convention representing characteristic laminae types, i.e. outer-inner_i-middle.  A `Geometry object` is created of mixed Pythonic types - specifically a namedtiple comprising floats, a list and a string (optional).\n",
    "\n",
    "We distinguish the latter *string* and coverted *object* types with the following naming conventions:\n",
    "\n",
    "- geometry string: raw string of the laminate geometry, e.g. `'400-200-800'`\n",
    "- Geometry object: `Geometry` class instance e.g. `<Geometry object (400-[200]-800)>`\n",
    "\n",
    "Names referencing geometry strings are lower-case: \n",
    "\n",
    "- `g`, `geo_inputs`, `geos` or `geos_full`, \n",
    "- `geos = ['400-[200]-800', '400-[100,100]-400S']`   \n",
    "\n",
    "Names referencing **`Geometry` objects** are capatlized: \n",
    "\n",
    "- `G`, `Geo_objects`, `Geos` or `Geos_full`, \n",
    "- `G = la.input_.Geometry(FeatureInput)`\n",
    "\n",
    "\n",
    "### `BaseDefaults` class\n",
    "\n",
    "This class is essentially a storage for common geometry strings and Geometry objects.  Placing them here enables simple inheritance of starter objects when using the API.  \n",
    "\n",
    "\n",
    "There are two main dicts which are stored as instance attributes: `geo_inputs` and `Geo_objects`\n",
    "\n",
    "#### `geo_inputs`\n",
    "\n",
    "This is a simple dict of common geometry strings with keys named by the number of plies.  Again the number of plies is determined by $$2(outer + inner) + middle$$.  Here is an example `geo_inputs` dict:\n",
    "\n",
    "```\n",
    "self.geo_inputs = {\n",
    "    '1-ply': ['0-0-2000', '0-0-1000'],\n",
    "    '2-ply': ['1000-0-0'],\n",
    "    '3-ply': ['600-0-800', '600-0-400S'],\n",
    "    '4-ply': ['500-500-0', '400-[200]-0'],\n",
    "    '5-ply': ['400-200-800', '400-[200]-800', '400-200-400S'],\n",
    "    '6-ply': ['400-[100,100]-0', '500-[250,250]-0'],\n",
    "    '7-ply': ['400-[100,100]-800', '400-[100,100]-400S'],\n",
    "    '9-ply': ['400-[100,100,100]-800'],\n",
    "    '10-ply': ['500-[50,50,50,50]-0'],\n",
    "    '11-ply': ['400-[100,100,100,100]-800'],\n",
    "    '13-ply': ['400-[100,100,100,100,100]-800'],\n",
    "}\n",
    "```\n",
    "Additional keys are added to this dict such as 'geos_even', 'geos_odd' and 'geos_all' which create new key-value pairs of groups for even, odd and all geometry strings.  Notice the naming placement of 's': \"geo_inputs\" is the base dict while \"geos_<group>\" is a grouping of existing dict values appended to the dict.  Therefore an author or developer could extend either the base or appended  dict items.\n",
    "\n",
    "\n",
    "#### `Geo_objects`\n",
    "\n",
    "This is a lazy dict.  All entries of `geo_inputs` are automatically converted and stored as Geometry objects.  The purpose here is to eliminate the added step of calling Geometry to convert strings.  Both this dict and the `geo_inputs` dict are created using similar private methods, so there mechanisms are parallel.\n",
    "\n",
    "#### Subclassing\n",
    "\n",
    "The remaining defeaults such as `load_params`, `mat_props` and `FeatureInput` are specific to experimental setups and cannot be generalized effectively.  However, this class can be subclassed into a custom `Defaults` class by the author.  See the Authour Documentation for examples of subclassing.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. important ::\n",
    "        \n",
    "    DEV: Only add geometry strings to `geo_inputs`.  Removing or \"trimming\" these dicts may break tests."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. important ::\n",
    "\n",
    "    In future versions, ``load_params``, ``mat_props`` and ``FeatureInput`` will be added to BaseDefaults() as attributes to partake in inheritance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Module: `distributions`\n",
    "\n",
    "### `Case` class\n",
    "\n",
    "The `Case` class translates user information into managable, analytical units.  A `Case` object is:\n",
    "\n",
    "1. instantiated \n",
    "2. user info is applied such as geoemtry strings, model name, etc.\n",
    "3. method and proerties are accessed, such as `plot()` and `total`\n",
    "\n",
    "Here is an idiomatic example of the latter characteristics:\n",
    "\n",
    "    case = la.distributions.Case(load_params, mat_props)\n",
    "    case.apply(geo_strings=None, model='Wilson_LT', **kwargs)\n",
    "    case.plot(**kwargs)\n",
    "\n",
    "The `case` instance accepts loading and material information and sets up their associated dicts.   Specific geometry strings and one model is applied to the case object.  This `apply()` method generates `LaminateModel` objects (`FeatureInput` objects are also made).  Information is parsed, calculated (such as layer thicknesses) and stored in attributes.   These attributes and methods are then accessible for performing analysis, most importantly the `plot()` method.\n",
    "\n",
    "Therefore, you can think of a case as an analytical unit comprising start up data converted to LaminateModel objects.\n",
    "\n",
    "### `Cases` class\n",
    "\n",
    "The `Cases` class supplies options for manipulating multiple case objects.  For example, set operations can be performed on multiple cases.  In this context, each `case` is termed a `caselet` and typically correlated with a matplotlib subplot.  Here is an idiomatic example:\n",
    "\n",
    "    import lamana as la\n",
    "    \n",
    "    bdft = la.input_.BaseDefaults()\n",
    "    cases = Cases(bdft.geo_inputs['geos_all'], ps=[2,3,4])\n",
    "\n",
    "The latter code builds cases for all geometry strings contained in the `BaseDefaults()` class, one for each `p` number of datapoints.  Therefore in this example *dozens* of analytical units are built with only three lines of code.  See LPEP 002 and LPEP 003 for the motivation and details on `Cases`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Module: `constructs`\n",
    "\n",
    "Principally, the `constructs` module builds a `LaminateModel` object.  Technically a `LaminateModel` is a [`pandas`](http://pandas.pydata.org/) DataFrames representing a physical laminate with a few helpful attributes.  DataFrames were chosen as the backend object because they allow for powerful data manipulation analyses and database/spreadsheet-like visualizations with simple methods.  \n",
    "\n",
    "Additionally, the `constructs` module computes laminate dimensional columns and compiles theoretical calculations handled by the complementary `theories` module.  Conventiently, all of this data is contained in tabular form within the DataFrame.  The column names are closely related to computational variables defined in the next sub-section.\n",
    "\n",
    "### Variable Classifications\n",
    "\n",
    "Before we discuss the Laminate structure, here we distinguish two ubiquitous variable categories used internally: \"Laminate\" and \"model\" variables.  In in a full laminate DataFrame, these categories comprise variables that are represented as columns.  The categories variables, columns and corresponding modules are illustrated in the image below and described in greater detail:\n",
    "\n",
    "![dataframe output](./_images/dataframe_output.png)\n",
    "\n",
    "An image of the output for a DataFrame and their labeled categories of columns (IDs, dimensionals and models).  The first two categories are computed by `constructs` classess; the models columns are computed by `theories` classes and models.  The highlighted blue text indicates user interaction.  Groups of rows are colored with alternating red and orange colors to distinguish separate layers.\n",
    "\n",
    "\n",
    "#### What distinguishes \"Laminate\" variables from \"Model\" variables\n",
    "\n",
    "- **Laminate** (or `constructs`) variables are responsible for building the laminate [stack](#First:-The-Stack-Class) and defining dimensions of the laminate.  Internally, these varibles will be semantically distinguished with one trailing underscore.\n",
    "    1. **ID**: variables related to layer and row identifications \n",
    "        1. `layer_`, `side_`, `matl_`, `type_`, `t_`\n",
    "    2. **Dimensional**: variables of heights relative to cross-sectional planes\n",
    "        1. `label_`, `h_`, `d_`, `intf_`, `k_`, `Z_`, `z_` \n",
    "- **Model** (or `theories`) variables: all remaining variables are relevant for LT calculations and defined from a given model. Since these variables are model-specific, theres is no particular semantic or naming format.  \n",
    "\n",
    "The finer granularity seen with model variables is not essential for typcial API use, but may be helpful when authoring custom code that integrates with LamAna. \n",
    "\n",
    "#### Further Details of Model Variables\n",
    "\n",
    "For more detailed discussions, model variables can be further divided into sub-categories.  There common subsets are as follows:\n",
    "\n",
    "    1. **User**: global variables delibrately set by the user at startup\n",
    "    2. **Inline**: variables used per lamina at a kth level (row)\n",
    "    3. **Global**: variables applied to the laminate, accessible by ks\n",
    "\n",
    "Although model variables are often particular to a chosen model, e.g Wilson_LT, there are some  general trends that may be adopted.  Some model variables are provided at startup by the user (user_vars).  Some variables are calculated for each row of the data within the table (inline_vars).  Some variables are calculated by the designated laminate theory model, which provide constants for remaining calculations (global_vars).  Global values would display as the same number for every row.  These constants are thus removed from the DataFrame, but they are stored internally within a `dict`.  The details of this storage are coded within each model module.  \n",
    "\n",
    "Global values are of particular importance to `FeatureInput` objects and when exporting meta data as dashboards in spreadsheets. In contrast, Inline values alter directly with the dimensional values thoroughout the lamainate thickness. Names of common variables used in `distributions` are organized below:\n",
    "\n",
    "*Model Variable Subsets*\n",
    "\n",
    "    Model_vars = {user_vars, inline_vars, global_vars}\n",
    "\n",
    "*Examples of Subsets of Model Variables*\n",
    "\n",
    "- user_vars   = [`mat_props`, `load_params`]\n",
    "- global_vars = [`v_eq`, `D_11T`, `D_12T`, `M_r`, `M_t`, `D_11p`, `D_12n`, `K_r`, `K_t`]\n",
    "- inline_vars = [`Q11`, `Q12`, `D11`, `D12`, `strain_r`, `strain_t`,\n",
    "    `stress_r`, `stress_t`, `stress_f`]\n",
    "\n",
    "TIP: Aside from user variables, all others are found as headers for columns \n",
    "in a DataFrame (or spreadsheet).\n",
    "\n",
    "### The `Laminate` Architecture\n",
    "\n",
    "This section will describe in greater detail how `LaminateModel`s are constructed.  \n",
    "\n",
    "When the user calls `case.apply()`, a number of objects are created.  We begin with a primitive `Stack`, which comprises skeletal components for building a `Laminate` DataFrame (also interally called an LFrame).  The phases for building a `LaminateModel` object are outlined below and outline the architecture of `constructs.Laminate` class.\n",
    "\n",
    "- Phase 1: build a primitive laminate (Stack)\n",
    "- Phase 2: calculate Laminate dimensional values (LFrame)\n",
    "- Phase 3: calculate laminate theory Model values (LMFrame aka `LaminateModel`)\n",
    "\n",
    "#### Phase 1: The `Stack` Class\n",
    "\n",
    "The purpose of the `Stack` class is to build a skeletal, precusor of a primitive `Laminate` object.  This class houses methods for parsing Geometry objects, ordering layers, adding materials labels for each layer and setting *expected* stress states for each tensile or compressive side.  `Stack` returns a namedtuple containing stack-related information (described below).\n",
    "\n",
    "For a given `Geometry` object instance (commonlly assigned to a capital \"G\") the `Stack().StackTuple` method  creates a namedtuple of the stack information.  This object contains attributes to access the:\n",
    "\n",
    "- stack `order`\n",
    "- the number of plies, `nplies`\n",
    "- the technical `name` for the laminate, \"4-ply\", \"5-ply\"\n",
    "- a convenient `alias` if any, e.g. \"Bilayer\", \"Trilayer\"\n",
    "\n",
    "The `stack` attribute accesses a dict of the laminate layers ordered from bottom to top.  Now although Python dicts are unsorted, this particular dict is sorted because each layer is enumerated and stored as keys to perserve the order, layer thickness and layer type (sometimes referred as \"ltype\").  \n",
    "\n",
    "```python\n",
    "\n",
    "Examples\n",
    "--------\n",
    ">>> import LamAna as la\n",
    ">>> G = la.input_.Geometry(['400-200-800'])\n",
    ">>> G\n",
    "<Geometry object (400-[200]-800)>\n",
    "\n",
    "Create a StackTuple and access its attributes\n",
    ">>> st = constructs.Stack(G).StackTuple    # converts G to a namedtuple\n",
    ">>> st.order                               # access namedtuple attributes\n",
    "{1: [400.0, 'outer'],\n",
    " 2: [200.0, 'inner']\n",
    " 3: [800.0, 'middle']\n",
    " 4: [200.0, 'inner']\n",
    " 5: [400.0, 'outer']}\n",
    ">>> st.nplies\n",
    "5\n",
    ">>> st.name\n",
    "'5-ply'\n",
    ">>> st.alias\n",
    "'standard'\n",
    "\n",
    "```\n",
    "\n",
    "#### Phase 2: The `Laminate` class\n",
    "\n",
    "The `Laminate` class simply builds a `LaminateModel` - an object containing all dimensional information of a physical `Laminate` **and** all theoretical calculations using a laminate theory `Model`, e.g. stress/strain.\n",
    "\n",
    "The `Laminate` class builds an LFrame object based on the skeletal layout of a stack parsed by and returned from the `Stack` class.  A `Geometry` object, material parameters and geometric parameters are all passed from the user in as a single  `FeatureInput` object - a dict of useful information that is passed between modules.  See [*More on `FeatureInput`*](#More-on-FeatureInput) for details.  Stack information is stored in an instance attribute called `Snapshot` and then converted to a set of DataFrames.  \n",
    "\n",
    "Therefore, the IDs and dimensional data are determined and computed by `Stack` and `Laminate`.  Combined, this information builds an LFrame.\n",
    "\n",
    "#### Phase 3: The `Laminate` class (continued)\n",
    "\n",
    "`Laminate` then calls the `theories` module which \"handshakes\" between the `Laminate` module and the custom module containing code of a user-specified, theoretical LT model.  It is common for a custom model to be named by the author, suffixed by the characters \"`_LT`\").  These computations update the Laminate DataFrame (`Laminate.LFrame`), creating a final `LaminateModel` (`Laminate.LMFrame`).  The complete workflow is summarized below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Summary of LaminateModel Workflow\n",
    "\n",
    "```python\n",
    "constructs :: class Stack --> class Laminate\n",
    "\n",
    "theories :: class BaseModel\n",
    "```\n",
    "\n",
    "Laminate object + \"Model\" object --> LaminateModel object\n",
    "\n",
    "\n",
    "Detailed workflow of `constructs-theories` interaction:\n",
    "```python\n",
    "class Stack --> StackTuple\n",
    " |\n",
    "class Laminate --> Snapshot, LFrame, LMFrame\n",
    " |\n",
    " | # Phase 1 : Instantiate; Determine Laminate ID Values\n",
    " | Laminate._build_snapshot(stack) --> Snapshot\n",
    " |     |\n",
    " |   Stack.add_materials(stack) \n",
    " |   Stack.stack_to_df(stack)        # first creation of the Laminate df\n",
    " |   Laminate._set_stresses(stack)    \n",
    " |\n",
    " | Laminate._build_laminate(snapshot) --> LFrame\n",
    " | \n",
    " | # Phase 2 : Calculate Laminate Dimensional Values\n",
    " | Laminate._update_columns._update_dimensions() --> LFrame (updated)\n",
    " |        label_, h_, d_, intf_, k_, z_, Z_\n",
    " |\n",
    " | # Phase 3 : Calculate Model Values\n",
    " | Laminate._update_columns._update_calculations() --> LMFrame\n",
    " |    theories.Model(Laminate)\n",
    " |    models.<selected model>\n",
    " |       _calc_stiffness()\n",
    " |       _calc_bending()\n",
    " |       _calc_moment()\n",
    " |       global_vars = [`v_eq`, `D_11T`, `D_12T`, ...]\n",
    " |       inline_vars = [`Q11`, `D11` `strain_r`, ...]\n",
    " |\n",
    "LaminateModel : df\n",
    "  \n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Details\n",
    "\n",
    "\n",
    "#### More on Material Stacking Order\n",
    "\n",
    "The material order is initially defined by the user `mat_props` dict in `distributions` and automatically parsed in the `input_` module.  Extracting order from a dict is not trivial, so the default sorting is alphabetical order.  This order is handled by converting the dict to a pandas index.  See `Stack.add_materials()` method for more details.\n",
    "\n",
    "As of 0.4.3d4, the user can partially override the default ordering by setting the `materials` property in the Case instance.  This allows simple control of the stacking order in the final laminate stack and `Laminate` objects. At the moment, a list of materials is cycled through; more customizations have not been implemented yet.\n",
    "\n",
    "```python\n",
    ">>> case.material\n",
    "['HA', 'PSu']                                     # alphabetical order\n",
    ">>> case.material = ['PSu', 'HA']                 # overriding order    \n",
    ">>> case.material\n",
    "['PSu', 'HA']\n",
    ">>> case.apply(...)             \n",
    "<materials DataFrame>                             # cycles the stacking order\n",
    "\n",
    "```\n",
    "\n",
    "#### More on `Laminate`\n",
    "\n",
    "Using `Laminate._build_snapshot()`, the instance stack dict is converted to a DataFrame (`Snapshot`), giving a primitive view of the laminate geometry, idenfiers (IDs) and stacking order. This \"snapshot\" has the following ID columns of infornation, which are accessible to the user in a `Case` instance (see `distributions.Case.snapshot`):\n",
    "\n",
    "    Variables addressed: `layer_, matl_, type_, t_`\n",
    "\n",
    "From this snapshot, the DataFrame can is updated with new information.  For example, the sides on which to expected tensile and compressive stresses are located (`side_`) are assigned to a laminate through the `Laminate._set_stresses()` method.  This function accounts for DataFrames with even and odd rows.  For odd rows, 'None' is assigned to the neutral axis, implying \"no stress\".\n",
    "\n",
    "    Variables addressed: `side_`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note ::\n",
    "\n",
    "    This stress assignment is a general designation, coarsely determined by which side of the netural axis a row is found.  The rigorous or finite stress state must be calculated through other analytical tools means such as Finite Element Analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, the DataFrame is further updated with columns of dimensional data (from Dimensional variables) and laminate theory data (from model variables).  The current `LaminateModel` object is made by calling `Laminate._update_columns._build_laminates()` which updates the snapshot columns to build two DataFrame objects:\n",
    "\n",
    "Here are similarities between the laminate data columns and the its objects:\n",
    "\n",
    "- `Snapshot`: primiate DataFrame of the Stack (see materials, layer info order).\n",
    "- `LFrame`: updated `Snapshot` of IDs and dimensionals.\n",
    "- `LMFrame`: updated LFrame with models computed columns.\n",
    "\n",
    "![laminate objects](./_images/laminate_objects.png)\n",
    "\n",
    "`LMFrame` is the paramount data structure of interest containing all IDs, Dimensional and Model variables and `p` number of rows pertaining to data points within a given lamina.  \n",
    "\n",
    "Dimensional variable columns are populated through the `Laminate._update_columns._update_dimensions()` method, which contains algorithms for calculating realative and absolute heights, thicknesses and midplane distances relative to the neutral axis.  These columns contain dimensional data that are determined independent from the laminate theory model. \n",
    "\n",
    "    Variables addresed: `label_, h_, d_, intf_, k_, Z_, z_`\n",
    "\n",
    "These variables are defined in the Laminate class docstring.  See *More on label_* to understand the role of points, `p` and their relationship to DataFrame rows.  \n",
    "\n",
    "Finally Data variable columns are populated using `Laminate._update_columns._update_calculations().`  These columnns contain data based on calculations from laminate theory for a selected model.  Here global_vars and inline_vars are calculated.\n",
    "\n",
    "    Variables addressed:\n",
    "    --------------------\n",
    "    global_vars = [`v_eq, D_11T, D_12T, M_r, M_t, D_11p, D_12n, K_r, K_t`] --> FeatureInput['Global'] (dict entry)\n",
    "    \n",
    "    inline_vars = [`Q11, Q12, D11, D12, strain_r, strain_t, stress_r, stress_t, stress_f`] --> LaminateModel object (DataFrame)\n",
    "    \n",
    "\n",
    "#### More on `FeatureInput`\n",
    "\n",
    "A Feature module defines a `FeatureInput` object. \n",
    "\n",
    "For `distributions`, it is defined in `Case`. `FeatureInput`s contain information that is passed between objects.  For instance, this object transfers user input data in `distributions` (converted in `input_`) to the `constructs` module to build the laminate stack and populate ID and dimensional columns. A FeatureInput from `distributions` looks like the following (as of 0.4.4b).\n",
    "```python\n",
    "FeatureInput = {\n",
    "    'Geometry': <Geometry object>,\n",
    "    'Loading': <load_params dict>,\n",
    "    'Materials': <mat_props dict>,\n",
    "    'Custom': <undefined>,\n",
    "    'Model': <string>,\n",
    "    'Globals': <dict>,\n",
    "}\n",
    "```                    \n",
    "After calculating model data, the \"Globals\" key is updated containing all necessary `globabl_vars`.  These variables are constant and are necessary for further calculations of `inline_vars`.  Here is an example of Global variables key-value pair in FeatureInput.\n",
    "\n",
    "```python\n",
    "FeatureInput['Globals'] = [v_eq, D_11T, D_12T, M_r, M_t, D_11p, D_12n, K_r, K_t]\n",
    "```\n",
    "\n",
    "#### More on `label_`\n",
    "\n",
    "See LPEP 001.02 for standards of API units.\n",
    "\n",
    "For this explanation, imagine we transverse the absolute height of the laminate at different cross-sectional planes.  The values of inline stress points are calculated along different planes throughout the laminate thickness. What happens at interfaces where two materials meet with different stresses?  How are these two stress points differentiated in a DataFrame or in a plot?  For plotting purposes, we need to define diferent types of points.  Here we define some rulse and four types of points found within a (i.e. DataFrame rows):\n",
    "\n",
    "1. interfacial - point on unbound outer surfaces and bound internal surfaces.\n",
    "2. internal - point with the lamina thickness between interfaces \n",
    "3. discontinuity - point on bounded interfaces pertaining to an adjacent lamina\n",
    "4. neutralaxis - the middle, symmetric axial plane\n",
    "\n",
    "How these points are distributed depends on their locations within each lamina and whether they are located on the tensile or compressive `side_`.  The neutral axis exists in physical laminates, but they are only represented as a row in DataFrames of odd ply, odd p laminates; they are not displayed in even laminates.  The image below illustrates the different points from above with respect to `k_` (the fractional height for a given layer).\n",
    "\n",
    "![points](./_images/points.png)\n",
    "\n",
    "Notice various layers have different point types.\n",
    "\n",
    "- Middle layers have two interfacial points, no discontinuities and a neutral axis.\n",
    "- All other layers have one interfacial point with a discontinuity if p >= 2.\n",
    "- All layers may (or may not) have internal points.\n",
    "- Monoliths do not have discontinuities"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    Only the interfacial points can be theoreticlly verified, representing the maximum principal strains and stresses.  The internal and discontinuity points are merely used by matplotlib to connect the points, assuming a linear stress distribution.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    The midplane z height (`z_`) for discontinuities assumes a non-zero, lower limit value equal to the Z_ height of the bounding layer.  This value should be verified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More on `IndeterminateError`\n",
    "\n",
    "An `IndeterminateError` is thrown in cases where values cannot be calculated.  An `INDET` keyword is given as values in DataFrame cells.  An example for such an error is determining the stress state `side_` for a monolith with one data point (nplies=1, p=1).  From a design perspective, the location of the point is ambiguous, either one one interface, but more intuitively at the neutral access.  At such a position, the value of stress would report zero, which is misleading for the true stress state of the monolith.  Therefore, the `InderminateError` is thrown, recommending at least p = 2 for disambiguated stress calculations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Module: `theories`\n",
    "\n",
    "Laminate theory is merged with dimensional data to create a `LaminateModel`.\n",
    "\n",
    "\n",
    "### `LaminateModel` Handling\n",
    "\n",
    "For clarify, an illustration of LaminateModel handling is shown below.  \n",
    "\n",
    "The `Laminate` DataFrame (LFrame) is passed from `constructs` to `theories`.  If successful the `LaminateModel` is returned to `constructs`; otherwise an exception is thrown, consumed and the `Laminate` is returned unchanged (LFrame).  \n",
    "\n",
    "![theories flowchart](./_images/diagram_theories.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    The term repr for <`LaminateModel object`> remains constant refering to a post-theories operation, whether LMFrame is updated with Model columns or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `Laminate._update_columns._update_calculations()` (represented as `Laminate.foo()`) is called, an instance of the `Laminate` `self` (shown as \"x\") is passed to `theories.handshake()` (black arrow).  This function handles all updates to the primitive `Laminate` DataFrame (LFrame) which comprise IDs and Dimensional columns only.  The `Laminate` gives the models author full access to its attributes.  From here, `theories.handshakes()` searches within the models directory for a model (grey, dashed arrows) specified by the user at the time of instantiation, i.e. `Case.apply(*args, model=<model_name>).` \n",
    "\n",
    "A model is simply a module containing code that handles laminate theory calculations.  The purpose of the model is to update the primitive LFame with LT calculations.  `handshake()` automatically distinguishes whether the author implemented a class-style or function-style model.  The **most important hook method/function is `_use_model_()`**, which must be present somewhere inside the model module and must return a tuple containing:\n",
    "\n",
    "    - the updated Laminate DataFrame with model data columns (a.k.a. `LaminateModel`)\n",
    "    - the `FeatureInput` with updated 'Globals' key - a dict of calculated constants, used in exported reports (see output_ section). \n",
    "\n",
    "Finally, the `Laminate.LMFrame` attribute is updated with the new `LaminateModel` and `FeatureInput` (green arrow).  However, if exceptions are raised, `Laminate._update_calculations()` handles reverting the LMFrame to a copy of LFrame, printing a warning and minor traceback informing the author to refactor the code.  This is commom for Laminates with `p`=1, which detects an INDET in middle layers and must revert to LFrame.   The `handshake()` method for more  details on Exceptions.   \n",
    "\n",
    "### Custom Models\n",
    "\n",
    "Sometimes, classical laminate theory need to be modified to fit a specific set of conditions.\n",
    "\n",
    "A powerful, extensible option of the LamAna package is user implementation of their own laminate theory models.  A library of these custom models (as well as the defaults) are stored in the `models` directory (sub-package).  This exchange is possbile since the `theories` module handshakes between the `constructs` module and the selected model from the `models` sub-package.  All models, code, related exceptions, global model code and defaults are housed in a Models module.  `theories` then merges the model calculations with the passed in `Laminate` to calculate  data columns in the `LaminateModel` object.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Module: `output_`\n",
    "\n",
    "A summary of `output` objects\n",
    "\n",
    "| Object | Purpose |\n",
    "|:------ |:-------- |\n",
    "| `SinglePlot` | Stress distribution for a single geometry |\n",
    "| `MultiPlot` | Stress distributions for a multiple geometries |\n",
    "| `HalfPlot` | Partial plot of either compression or tension side |\n",
    "| `QuarterPlot` | Partial halfplot excluding side without data |\n",
    "| `PanelPlot` | A series of subplots side-by-side |\n",
    "| `RatioPlot` | Ratio thickness plot; prinicipal stress vs. ratio |\n",
    "| `PredictPlot` | Plot of experimental failure load or stress vs. middle layer princ. stress |\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    Development is beta for this module, therefore these objects are not yet implemented.  The majority of plotting options are handled by temporary private functions called _distribplot() and _multiplot().  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
